Week 1: Importing datasets 

import pandas as pd

url = "..."

df = pd.read_csv(url,header=None)

df: prints the entire dataframe
df.head(n) to show the first n rows
df.tail(n) to show the bottom n rows

headers = ["...","...",...,"..."]
df.columns = headers : replace default headers 

path = "..."
df.to_csv(path) : preserve progress anytime by saving modified dataset 

Reading dataset: 
pd.read_csv()
pd.read_json()
pd.read_excel()
pd.read_sql()

Save:
df.to_csv()
df.to_json()
df.to_excel()
df.to_sql()

df.dtypes : to check data types
df.describe() : returns a statistical summary / include="all" : provides full summary statistics
df.info() : provide a concise summary of your dataframe
df[['column_name1','column_name2',column_name3']].describe()

Connection methods: 
cursor() : method returns a new cursor object using the connection
commit(): method is used to commit any pending transaction to the database 
rollback(): method causes the database to roll back to the start of any pending transaction 
close(): method is used to close a database connection

df1.reaplce('?',np.NaN): replace whatever value in '?' with value in 'NaN"
df = df1.dropna(subset=["price"],axis=0)

